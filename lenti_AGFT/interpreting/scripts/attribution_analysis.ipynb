{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribution Analysis — AlphaGenome FT LentiMPRA\n",
    "\n",
    "Compute and visualize attributions for our fine-tuned AlphaGenome model on LentiMPRA K562.\n",
    "\n",
    "**Methods available:**\n",
    "- **Gradient SHAP**: Expected gradients with Altschul-Erickson dinucleotide shuffle (`deepshap.py`)\n",
    "- **Gradient × Input**: Standard gradient-based\n",
    "- **ISM**: In silico mutagenesis (wildtype-base importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX devices: [CudaDevice(id=0)]\n"
     ]
    }
   ],
   "source": [
    "import os, sys, json\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from pathlib import Path\n",
    "\n",
    "# Project paths\n",
    "PROJ_DIR = Path(\"/grid/wsbs/home_norepl/pmantill/LentiMPRA_mcs/LentiMoCon\")\n",
    "RESULTS_DIR = PROJ_DIR / \"lenti_AGFT\" / \"training\" / \"results\"\n",
    "DATA_DIR = str(PROJ_DIR / \"test_run_lenti_data\")\n",
    "\n",
    "# Add custom head/data modules to path (EncoderMPRAHead, LentiMPRADataset)\n",
    "sys.path.insert(0, str(PROJ_DIR / \"alphagenome_FT_MPRA\"))\n",
    "# Add interpreting scripts to path (deepshap module)\n",
    "sys.path.insert(0, str(PROJ_DIR / \"lenti_AGFT\" / \"interpreting\" / \"scripts\"))\n",
    "\n",
    "# HuggingFace cache\n",
    "os.environ[\"HF_HOME\"] = os.path.expanduser(\"~/Liver_AGFT/.weights/huggingface\")\n",
    "\n",
    "# Patch: use HuggingFace instead of Kaggle for base model downloads\n",
    "from alphagenome_research.model import dna_model\n",
    "dna_model.create_from_kaggle = dna_model.create_from_huggingface\n",
    "\n",
    "from deepshap import deep_lift_shap\n",
    "\n",
    "print(f\"JAX devices: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "Set the model name and attribution parameters here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: second_2stageig\n",
      "Checkpoint: best_stage2\n",
      "DeepSHAP: 20 refs x 50 IG steps = 1000 grad evals\n",
      "Head config: pooling=flatten, nl=1024, do=0.1, act=relu\n"
     ]
    }
   ],
   "source": [
    "# ---- Configuration ----\n",
    "MODEL_NAME = \"second_2stageig\"          # Model to analyze\n",
    "CHECKPOINT_STAGE = \"best_stage2\"         # \"best\" (stage 1) or \"best_stage2\"\n",
    "CELL_TYPE = \"K562\"\n",
    "ATTRIBUTION_METHOD = \"deepshap\"          # \"deepshap\", \"gradient_x_input\", or \"ism\"\n",
    "N_SEQUENCES = 5                          # Number of top sequences to analyze\n",
    "N_SHAP_REFERENCES = 20                    # Number of shuffle references for DeepSHAP\n",
    "N_IG_STEPS = 50                           # Integration steps per reference (higher = more accurate)\n",
    "HEAD_NAME = \"mpra_head\"\n",
    "PROMOTER_CONSTRUCT_LENGTH = 281\n",
    "\n",
    "# Paths\n",
    "model_dir = RESULTS_DIR / MODEL_NAME\n",
    "checkpoint_dir = model_dir / \"checkpoints\" / CHECKPOINT_STAGE\n",
    "output_dir = PROJ_DIR / \"lenti_AGFT\" / \"interpreting\" / \"results\" / MODEL_NAME\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load model hyperparameters\n",
    "with open(model_dir / \"args.json\") as f:\n",
    "    args_json = json.load(f)\n",
    "hp = args_json[\"hp\"]\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Checkpoint: {CHECKPOINT_STAGE}\")\n",
    "print(f\"DeepSHAP: {N_SHAP_REFERENCES} refs x {N_IG_STEPS} IG steps = {N_SHAP_REFERENCES * N_IG_STEPS} grad evals\")\n",
    "print(f\"Head config: pooling={hp['pooling_type']}, nl={hp['nl_size']}, do={hp['dropout']}, act={hp['activation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from /grid/wsbs/home_norepl/pmantill/LentiMPRA_mcs/LentiMoCon/lenti_AGFT/training/results/second_2stageig/checkpoints/best_stage2\n",
      "  Custom heads: ['mpra_head']\n",
      "  Model type: Full model\n",
      "Loading full model from checkpoint...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86c2db6da0346408bc5bf807e5f78af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8efc584c8d674b3ea6ccd4b3252e2127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/grid/wsbs/home_norepl/pmantill/LentiMPRA_mcs/LentiMoCon/mpra_agft/lib/python3.11/site-packages/pyfaidx/__init__.py:589: UserWarning: for fsspec: HTTPFileSystem assuming index is current\n",
      "  warnings.warn(\"for fsspec: %s assuming index is current\" % type(self._fs).__name__)\n",
      "/grid/wsbs/home_norepl/pmantill/LentiMPRA_mcs/LentiMoCon/mpra_agft/lib/python3.11/site-packages/pyfaidx/__init__.py:589: UserWarning: for fsspec: HTTPFileSystem assuming index is current\n",
      "  warnings.warn(\"for fsspec: %s assuming index is current\" % type(self._fs).__name__)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Checkpoint loaded successfully\n",
      "  Total parameters: 455,176,326\n",
      "Model loaded from /grid/wsbs/home_norepl/pmantill/LentiMPRA_mcs/LentiMoCon/lenti_AGFT/training/results/second_2stageig/checkpoints/best_stage2\n",
      "Custom heads: ['mpra_head']\n",
      "Total parameters: 455,176,326\n"
     ]
    }
   ],
   "source": [
    "from alphagenome.models import dna_output\n",
    "from alphagenome_ft import (\n",
    "    register_custom_head,\n",
    "    load_checkpoint,\n",
    "    CustomHeadConfig,\n",
    "    CustomHeadType,\n",
    ")\n",
    "from src import EncoderMPRAHead, LentiMPRADataset\n",
    "\n",
    "# Register head with same config as training\n",
    "nl_size = hp[\"nl_size\"] if isinstance(hp[\"nl_size\"], list) else [hp[\"nl_size\"]]\n",
    "head_metadata = {\n",
    "    \"center_bp\": hp[\"center_bp\"],\n",
    "    \"pooling_type\": hp[\"pooling_type\"],\n",
    "    \"nl_size\": nl_size,\n",
    "    \"do\": hp[\"dropout\"],\n",
    "    \"activation\": hp[\"activation\"],\n",
    "}\n",
    "register_custom_head(\n",
    "    HEAD_NAME, EncoderMPRAHead,\n",
    "    CustomHeadConfig(\n",
    "        type=CustomHeadType.GENOME_TRACKS,\n",
    "        output_type=dna_output.OutputType.RNA_SEQ,\n",
    "        num_tracks=1, metadata=head_metadata,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Load fine-tuned checkpoint (Kaggle->HuggingFace patch applied in setup cell)\n",
    "model = load_checkpoint(\n",
    "    str(checkpoint_dir),\n",
    "    base_model_version=\"all_folds\",\n",
    "    init_seq_len=PROMOTER_CONSTRUCT_LENGTH,\n",
    ")\n",
    "print(f\"Model loaded from {checkpoint_dir}\")\n",
    "print(f\"Custom heads: {model._custom_heads}\")\n",
    "print(f\"Total parameters: {model.count_parameters():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 19670 samples for test split\n",
      "Test dataset: 19670 sequences\n",
      "\n",
      "Top 5 sequences by activity:\n",
      "  1. idx=6277, activity=2.8380\n",
      "  2. idx=3320, activity=2.5780\n",
      "  3. idx=3637, activity=2.2870\n",
      "  4. idx=9113, activity=2.2810\n",
      "  5. idx=5605, activity=2.2680\n"
     ]
    }
   ],
   "source": [
    "test_ds = LentiMPRADataset(\n",
    "    model=model,\n",
    "    path_to_data=DATA_DIR,\n",
    "    cell_type=CELL_TYPE,\n",
    "    split=\"test\",\n",
    "    random_shift=False,\n",
    "    reverse_complement=False,\n",
    ")\n",
    "print(f\"Test dataset: {len(test_ds)} sequences\")\n",
    "\n",
    "# Find top sequences by activity\n",
    "activities = [(i, float(test_ds[i][\"y\"])) for i in range(len(test_ds))]\n",
    "activities.sort(key=lambda x: x[1], reverse=True)\n",
    "top_seqs = activities[:N_SEQUENCES]\n",
    "\n",
    "print(f\"\\nTop {N_SEQUENCES} sequences by activity:\")\n",
    "for rank, (idx, act) in enumerate(top_seqs, 1):\n",
    "    print(f\"  {rank}. idx={idx}, activity={act:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_one_hot(one_hot_seq):\n",
    "    \"\"\"Convert one-hot encoded sequence back to DNA string (A=0, C=1, G=2, T=3).\"\"\"\n",
    "    if one_hot_seq.ndim == 3:\n",
    "        one_hot_seq = one_hot_seq[0]\n",
    "    base_map = {0: 'A', 1: 'C', 2: 'G', 3: 'T'}\n",
    "    return ''.join(base_map[int(jnp.argmax(one_hot_seq[i]))] for i in range(one_hot_seq.shape[0]))\n",
    "\n",
    "\n",
    "def prepare_sample(dataset, idx):\n",
    "    \"\"\"Get a sample ready for attribution (batch dim, JAX arrays).\"\"\"\n",
    "    sample = dataset[idx]\n",
    "    seq = jnp.array(sample[\"seq\"])\n",
    "    if seq.ndim == 2:\n",
    "        seq = seq[None, :, :]  # add batch dim\n",
    "    org = jnp.array(sample[\"organism_index\"])\n",
    "    if org.ndim == 0:\n",
    "        org = org[None]\n",
    "    seq_str = decode_one_hot(seq)\n",
    "    return seq, org, seq_str, float(sample[\"y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4b. DeepLIFT Convergence Check\n",
    "\n",
    "Verify the sum rule: `sum(attr * input) ≈ f(input) - mean(f(references))` for the first sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IG-SHAP sum rule check (n_refs=50, n_steps=50):\n",
      "  sum(attr) [all channels]   = 2.249261\n",
      "  f(input) - mean(f(refs))   = 2.214248\n",
      "  Difference                 = 0.035013\n",
      "  Relative error             = 1.5813%\n",
      "  Total grad evals           = 2500\n"
     ]
    }
   ],
   "source": [
    "import importlib, deepshap\n",
    "importlib.reload(deepshap)\n",
    "from deepshap import deep_lift_shap, dinucleotide_shuffle, _build_compute_output\n",
    "\n",
    "# Use first top sequence — fewer refs for quick check (each does n_steps grad evals)\n",
    "seq, org, seq_str, act = prepare_sample(test_ds, top_seqs[0][0])\n",
    "n_check = 50\n",
    "n_steps = 50\n",
    "\n",
    "# Compute attributions (integrated gradients per reference)\n",
    "attr = deep_lift_shap(model, seq, org, HEAD_NAME,\n",
    "                      n_shuffles=n_check, n_steps=n_steps, random_state=42)\n",
    "\n",
    "# Sum rule: sum over ALL positions and ALL 4 channels = f(x) - mean(f(refs))\n",
    "attr_sum = float(np.sum(np.array(attr)))\n",
    "\n",
    "# f(input)\n",
    "compute_output = _build_compute_output(model, org, HEAD_NAME)\n",
    "pred_input = float(compute_output(seq))\n",
    "\n",
    "# mean(f(references)) — same seed -> same references as deep_lift_shap\n",
    "refs = dinucleotide_shuffle(np.array(seq[0]), n=n_check, rng=np.random.default_rng(42))\n",
    "ref_preds = []\n",
    "for r in range(n_check):\n",
    "    ref_seq = jnp.array(refs[r:r+1])\n",
    "    ref_preds.append(float(compute_output(ref_seq)))\n",
    "pred_ref_mean = np.mean(ref_preds)\n",
    "\n",
    "expected = pred_input - pred_ref_mean\n",
    "print(f\"IG-SHAP sum rule check (n_refs={n_check}, n_steps={n_steps}):\")\n",
    "print(f\"  sum(attr) [all channels]   = {attr_sum:.6f}\")\n",
    "print(f\"  f(input) - mean(f(refs))   = {expected:.6f}\")\n",
    "print(f\"  Difference                 = {abs(attr_sum - expected):.6f}\")\n",
    "print(f\"  Relative error             = {abs(attr_sum - expected) / (abs(expected) + 1e-10):.4%}\")\n",
    "print(f\"  Total grad evals           = {n_check * n_steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compute Attributions & Visualize\n",
    "\n",
    "For each top sequence, compute all three attribution methods and generate a 2-column comparison figure (full attribution logos + WT-only logos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Sequence 1/5: idx=6277, activity=2.8380\n",
      "============================================================\n",
      "  Length: 281bp\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmp980k_n25.png\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmp7jfgwrq5.png\n",
      "  Computed DeepSHAP\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmpvk60pte8.png\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmphtk4a30t.png\n",
      "  Computed Grad x Input\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmpmuk16psl.png\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmp17esddq9.png\n",
      "  Computed ISM\n",
      "  Saved: /grid/wsbs/home_norepl/pmantill/LentiMPRA_mcs/LentiMoCon/lenti_AGFT/interpreting/results/fastdrop/seq6277/method_comparison.png\n",
      "\n",
      "============================================================\n",
      "Sequence 2/5: idx=3320, activity=2.5780\n",
      "============================================================\n",
      "  Length: 281bp\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmp4zyttmbh.png\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmpvavdaa7h.png\n",
      "  Computed DeepSHAP\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmpks_9kk8g.png\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmpy553sevx.png\n",
      "  Computed Grad x Input\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmpy6o557el.png\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmp79zd9fk8.png\n",
      "  Computed ISM\n",
      "  Saved: /grid/wsbs/home_norepl/pmantill/LentiMPRA_mcs/LentiMoCon/lenti_AGFT/interpreting/results/fastdrop/seq3320/method_comparison.png\n",
      "\n",
      "============================================================\n",
      "Sequence 3/5: idx=3637, activity=2.2870\n",
      "============================================================\n",
      "  Length: 281bp\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmp_bvwvn8s.png\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmp0yt52spg.png\n",
      "  Computed DeepSHAP\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmpiwkayslf.png\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmpycynkpue.png\n",
      "  Computed Grad x Input\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmpwlzkgvl5.png\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmp9qwghqih.png\n",
      "  Computed ISM\n",
      "  Saved: /grid/wsbs/home_norepl/pmantill/LentiMPRA_mcs/LentiMoCon/lenti_AGFT/interpreting/results/fastdrop/seq3637/method_comparison.png\n",
      "\n",
      "============================================================\n",
      "Sequence 4/5: idx=9113, activity=2.2810\n",
      "============================================================\n",
      "  Length: 281bp\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmp3g37ng4z.png\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmp605eun2f.png\n",
      "  Computed DeepSHAP\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmp3t5i6rka.png\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmpxymicm10.png\n",
      "  Computed Grad x Input\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmpoznei__r.png\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmpk6cq8ai7.png\n",
      "  Computed ISM\n",
      "  Saved: /grid/wsbs/home_norepl/pmantill/LentiMPRA_mcs/LentiMoCon/lenti_AGFT/interpreting/results/fastdrop/seq9113/method_comparison.png\n",
      "\n",
      "============================================================\n",
      "Sequence 5/5: idx=5605, activity=2.2680\n",
      "============================================================\n",
      "  Length: 281bp\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmpqchnma_d.png\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmpydzcogy0.png\n",
      "  Computed DeepSHAP\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmp37d_4whh.png\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmpvjo1avvw.png\n",
      "  Computed Grad x Input\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmpvrpqpzjv.png\n",
      "Sequence logo saved to: /tmp/slurm_tmp/703917/tmplvf6bxae.png\n",
      "  Computed ISM\n",
      "  Saved: /grid/wsbs/home_norepl/pmantill/LentiMPRA_mcs/LentiMoCon/lenti_AGFT/interpreting/results/fastdrop/seq5605/method_comparison.png\n",
      "\n",
      "All outputs saved to: /grid/wsbs/home_norepl/pmantill/LentiMPRA_mcs/LentiMoCon/lenti_AGFT/interpreting/results/fastdrop\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "from PIL import Image\n",
    "import tempfile\n",
    "\n",
    "for rank, (seq_idx, activity) in enumerate(top_seqs, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Sequence {rank}/{N_SEQUENCES}: idx={seq_idx}, activity={activity:.4f}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    seq, org, seq_str, act = prepare_sample(test_ds, seq_idx)\n",
    "    print(f\"  Length: {len(seq_str)}bp\")\n",
    "\n",
    "    methods = {\n",
    "        \"DeepSHAP\": lambda: jnp.array(deep_lift_shap(\n",
    "            model, seq, org, HEAD_NAME,\n",
    "            n_shuffles=N_SHAP_REFERENCES, n_steps=N_IG_STEPS,\n",
    "            random_state=42, hypothetical=False,\n",
    "        )),\n",
    "        \"Grad x Input\": lambda: model.compute_input_gradients(\n",
    "            sequence=seq, organism_index=org, head_name=HEAD_NAME, gradients_x_input=True,\n",
    "        ),\n",
    "        \"ISM\": lambda: model.compute_ism_attributions(\n",
    "            sequence=seq, organism_index=org, head_name=HEAD_NAME,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    logo_col1 = []  # full attribution logos\n",
    "    logo_col2 = []  # WT-only logos\n",
    "\n",
    "    for name, compute_fn in methods.items():\n",
    "        attr = jnp.float32(compute_fn())\n",
    "        if name != \"ISM\":\n",
    "            attr = attr - jnp.mean(attr, axis=-1, keepdims=True)\n",
    "\n",
    "        # Column 1: full attribution logo\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".png\", delete=False) as tmp:\n",
    "            tmp1 = tmp.name\n",
    "        model.plot_sequence_logo(\n",
    "            sequence=seq, gradients=attr, save_path=tmp1,\n",
    "            logo_type=\"weight\", mask_to_sequence=False, use_absolute=False,\n",
    "            title=f\"{name} — seq {seq_idx} (act={act:.3f})\",\n",
    "        )\n",
    "        logo_col1.append(Image.open(tmp1))\n",
    "\n",
    "        # Column 2: one-hot x attribution (WT base only)\n",
    "        attr_wt = attr * seq\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".png\", delete=False) as tmp:\n",
    "            tmp2 = tmp.name\n",
    "        model.plot_sequence_logo(\n",
    "            sequence=seq, gradients=attr_wt, save_path=tmp2,\n",
    "            logo_type=\"weight\", mask_to_sequence=True, use_absolute=False,\n",
    "            title=f\"{name} (WT only) — seq {seq_idx}\",\n",
    "        )\n",
    "        logo_col2.append(Image.open(tmp2))\n",
    "        print(f\"  Computed {name}\")\n",
    "\n",
    "    # Stitch into 2-column layout\n",
    "    n = len(methods)\n",
    "    w1 = max(img.width for img in logo_col1)\n",
    "    w2 = max(img.width for img in logo_col2)\n",
    "    row_h = max(max(img.height for img in logo_col1), max(img.height for img in logo_col2))\n",
    "    combined = Image.new(\"RGB\", (w1 + w2, row_h * n), \"white\")\n",
    "    for i in range(n):\n",
    "        combined.paste(logo_col1[i], (0, i * row_h))\n",
    "        combined.paste(logo_col2[i], (w1, i * row_h))\n",
    "\n",
    "    seq_out = output_dir / f\"seq{seq_idx}\"\n",
    "    seq_out.mkdir(parents=True, exist_ok=True)\n",
    "    save_path = seq_out / \"method_comparison.png\"\n",
    "    combined.save(save_path, dpi=(150, 150))\n",
    "    print(f\"  Saved: {save_path}\")\n",
    "\n",
    "    for img in logo_col1 + logo_col2:\n",
    "        img.close()\n",
    "\n",
    "print(f\"\\nAll outputs saved to: {output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpra_agft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
